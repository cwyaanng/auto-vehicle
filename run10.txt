nohup: ignoring input
Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.
See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
/home/wise/anaconda3/envs/carla/lib/python3.7/site-packages/gym/spaces/box.py:127: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
[forward] steps ÏôÑÎ£å: traveled=1998.2 m, steps=1000
[forward] Í≤ΩÎ°ú ÏÉùÏÑ±: 1001 wp, Ï¥ù Í±∞Î¶¨ 1998.2 m
[forward] Ï≤òÏùå 60Í∞ú Ïõ®Ïù¥Ìè¨Ïù∏Ìä∏Î•º Î≤ÑÎ¶º -> 931 wp ÎÇ®Ïùå
Using cuda device
target entropy : -1.5
cuda
dims:[35, 256, 256]
Î™®Îì† Îç∞Ïù¥ÌÑ∞ Î≤ÑÌçºÏóê Ï†ÄÏû•
critic pretrain => warm start
[Critic-MC] Epoch 1/25 | Loss: 0.0403
[Critic-MC] Epoch 2/25 | Loss: 0.0367
[Critic-MC] Epoch 3/25 | Loss: 0.0307
[Critic-MC] Epoch 4/25 | Loss: 0.0299
[Critic-MC] Epoch 5/25 | Loss: 0.0239
[Critic-MC] Epoch 6/25 | Loss: 0.0291
[Critic-MC] Epoch 7/25 | Loss: 0.0288
[Critic-MC] Epoch 8/25 | Loss: 0.0294
[Critic-MC] Epoch 9/25 | Loss: 0.0214
[Critic-MC] Epoch 10/25 | Loss: 0.0205
[Critic-MC] Epoch 11/25 | Loss: 0.0203
[Critic-MC] Epoch 12/25 | Loss: 0.0198
[Critic-MC] Epoch 13/25 | Loss: 0.0230
[Critic-MC] Epoch 14/25 | Loss: 0.0250
[Critic-MC] Epoch 15/25 | Loss: 0.0196
[Critic-MC] Epoch 16/25 | Loss: 0.0158
[Critic-MC] Epoch 17/25 | Loss: 0.0242
[Critic-MC] Epoch 18/25 | Loss: 0.0237
[Critic-MC] Epoch 19/25 | Loss: 0.0155
[Critic-MC] Epoch 20/25 | Loss: 0.0156
[Critic-MC] Epoch 21/25 | Loss: 0.0176
[Critic-MC] Epoch 22/25 | Loss: 0.0226
[Critic-MC] Epoch 23/25 | Loss: 0.0222
[Critic-MC] Epoch 24/25 | Loss: 0.0242
[Critic-MC] Epoch 25/25 | Loss: 0.0155
Î™®Îì† Ï£ºÌñâ Îç∞Ïù¥ÌÑ∞ actor behavioral cloning
[BC pretrain] step 0 | loss: 0.5966
[BC pretrain] step 500 | loss: 0.0183
[BC pretrain] step 1000 | loss: 0.0160
[BC pretrain] step 1500 | loss: 0.0167
[BC pretrain] step 2000 | loss: 0.0128
[BC pretrain] step 2500 | loss: 0.0146
[BC pretrain] step 3000 | loss: 0.0151
[BC pretrain] step 3500 | loss: 0.0172
[BC pretrain] step 4000 | loss: 0.0137
[BC pretrain] step 4500 | loss: 0.0152
[BC pretrain] step 5000 | loss: 0.0149
[BC pretrain] step 5500 | loss: 0.0143
[BC pretrain] step 6000 | loss: 0.0152
[BC pretrain] step 6500 | loss: 0.0151
[BC pretrain] step 7000 | loss: 0.0136
[BC pretrain] step 7500 | loss: 0.0127
[BC pretrain] step 8000 | loss: 0.0126
[BC pretrain] step 8500 | loss: 0.0146
[BC pretrain] step 9000 | loss: 0.0129
[BC pretrain] step 9500 | loss: 0.0102
[BC pretrain] step 10000 | loss: 0.0126
[BC pretrain] step 10500 | loss: 0.0095
[BC pretrain] step 11000 | loss: 0.0124
[BC pretrain] step 11500 | loss: 0.0101
[BC pretrain] step 12000 | loss: 0.0093
[BC pretrain] step 12500 | loss: 0.0086
[BC pretrain] step 13000 | loss: 0.0109
[BC pretrain] step 13500 | loss: 0.0095
[BC pretrain] step 14000 | loss: 0.0080
[BC pretrain] step 14500 | loss: 0.0116
[BC pretrain] step 15000 | loss: 0.0089
[BC pretrain] step 15500 | loss: 0.0102
[BC pretrain] step 16000 | loss: 0.0104
[BC pretrain] step 16500 | loss: 0.0116
[BC pretrain] step 17000 | loss: 0.0096
[BC pretrain] step 17500 | loss: 0.0102
[BC pretrain] step 18000 | loss: 0.0085
[BC pretrain] step 18500 | loss: 0.0076
[BC pretrain] step 19000 | loss: 0.0073
[BC pretrain] step 19500 | loss: 0.0121
[BC pretrain] step 20000 | loss: 0.0075
[BC pretrain] step 20500 | loss: 0.0067
[BC pretrain] step 21000 | loss: 0.0076
[BC pretrain] step 21500 | loss: 0.0075
[BC pretrain] step 22000 | loss: 0.0074
[BC pretrain] step 22500 | loss: 0.0075
[BC pretrain] step 23000 | loss: 0.0081
[BC pretrain] step 23500 | loss: 0.0074
[BC pretrain] step 24000 | loss: 0.0050
[BC pretrain] step 24500 | loss: 0.0068
[BC pretrain] step 25000 | loss: 0.0067
[BC pretrain] step 25500 | loss: 0.0073
[BC pretrain] step 26000 | loss: 0.0106
[BC pretrain] step 26500 | loss: 0.0055
[BC pretrain] step 27000 | loss: 0.0055
[BC pretrain] step 27500 | loss: 0.0081
[BC pretrain] step 28000 | loss: 0.0063
[BC pretrain] step 28500 | loss: 0.0069
[BC pretrain] step 29000 | loss: 0.0090
[BC pretrain] step 29500 | loss: 0.0072
[BC pretrain] step 30000 | loss: 0.0057
[BC pretrain] step 30500 | loss: 0.0092
[BC pretrain] step 31000 | loss: 0.0064
[BC pretrain] step 31500 | loss: 0.0069
[BC pretrain] step 32000 | loss: 0.0075
[BC pretrain] step 32500 | loss: 0.0061
[BC pretrain] step 33000 | loss: 0.0060
[BC pretrain] step 33500 | loss: 0.0059
[BC pretrain] step 34000 | loss: 0.0068
[BC pretrain] step 34500 | loss: 0.0071
[BC pretrain] step 35000 | loss: 0.0073
[BC pretrain] step 35500 | loss: 0.0065
[BC pretrain] step 36000 | loss: 0.0087
[BC pretrain] step 36500 | loss: 0.0057
[BC pretrain] step 37000 | loss: 0.0066
[BC pretrain] step 37500 | loss: 0.0075
[BC pretrain] step 38000 | loss: 0.0076
[BC pretrain] step 38500 | loss: 0.0067
[BC pretrain] step 39000 | loss: 0.0078
[BC pretrain] step 39500 | loss: 0.0074
[BC pretrain] step 40000 | loss: 0.0064
[BC pretrain] step 40500 | loss: 0.0061
[BC pretrain] step 41000 | loss: 0.0078
[BC pretrain] step 41500 | loss: 0.0046
[BC pretrain] step 42000 | loss: 0.0062
[BC pretrain] step 42500 | loss: 0.0069
[BC pretrain] step 43000 | loss: 0.0053
[BC pretrain] step 43500 | loss: 0.0074
[BC pretrain] step 44000 | loss: 0.0060
[BC pretrain] step 44500 | loss: 0.0056
[BC pretrain] step 45000 | loss: 0.0054
[BC pretrain] step 45500 | loss: 0.0073
[BC pretrain] step 46000 | loss: 0.0047
[BC pretrain] step 46500 | loss: 0.0048
[BC pretrain] step 47000 | loss: 0.0050
[BC pretrain] step 47500 | loss: 0.0057
[BC pretrain] step 48000 | loss: 0.0037
[BC pretrain] step 48500 | loss: 0.0039
[BC pretrain] step 49000 | loss: 0.0054
[BC pretrain] step 49500 | loss: 0.0066
[BC pretrain] step 50000 | loss: 0.0061
[BC pretrain] step 50500 | loss: 0.0055
[BC pretrain] step 51000 | loss: 0.0065
[BC pretrain] step 51500 | loss: 0.0068
[BC pretrain] step 52000 | loss: 0.0060
[BC pretrain] step 52500 | loss: 0.0046
[BC pretrain] step 53000 | loss: 0.0062
[BC pretrain] step 53500 | loss: 0.0061
[BC pretrain] step 54000 | loss: 0.0082
[BC pretrain] step 54500 | loss: 0.0062
[BC pretrain] step 55000 | loss: 0.0056
[BC pretrain] step 55500 | loss: 0.0064
[BC pretrain] step 56000 | loss: 0.0063
[BC pretrain] step 56500 | loss: 0.0080
[BC pretrain] step 57000 | loss: 0.0068
[BC pretrain] step 57500 | loss: 0.0053
[BC pretrain] step 58000 | loss: 0.0067
[BC pretrain] step 58500 | loss: 0.0060
[BC pretrain] step 59000 | loss: 0.0053
[BC pretrain] step 59500 | loss: 0.0069
[BC pretrain] step 60000 | loss: 0.0064
[BC pretrain] step 60500 | loss: 0.0063
[BC pretrain] step 61000 | loss: 0.0073
[BC pretrain] step 61500 | loss: 0.0069
[BC pretrain] step 62000 | loss: 0.0045
[BC pretrain] step 62500 | loss: 0.0085
[BC pretrain] step 63000 | loss: 0.0050
[BC pretrain] step 63500 | loss: 0.0030
[BC pretrain] step 64000 | loss: 0.0047
[BC pretrain] step 64500 | loss: 0.0053
[BC pretrain] step 65000 | loss: 0.0080
[BC pretrain] step 65500 | loss: 0.0058
[BC pretrain] step 66000 | loss: 0.0052
[BC pretrain] step 66500 | loss: 0.0044
[BC pretrain] step 67000 | loss: 0.0038
[BC pretrain] step 67500 | loss: 0.0047
[BC pretrain] step 68000 | loss: 0.0042
[BC pretrain] step 68500 | loss: 0.0054
[BC pretrain] step 69000 | loss: 0.0069
[BC pretrain] step 69500 | loss: 0.0050
[BC pretrain] step 70000 | loss: 0.0049
[BC pretrain] step 70500 | loss: 0.0076
[BC pretrain] step 71000 | loss: 0.0055
[BC pretrain] step 71500 | loss: 0.0053
[BC pretrain] step 72000 | loss: 0.0063
[BC pretrain] step 72500 | loss: 0.0047
[BC pretrain] step 73000 | loss: 0.0059
[BC pretrain] step 73500 | loss: 0.0050
[BC pretrain] step 74000 | loss: 0.0050
[BC pretrain] step 74500 | loss: 0.0037
[BC pretrain] step 75000 | loss: 0.0045
[BC pretrain] step 75500 | loss: 0.0042
[BC pretrain] step 76000 | loss: 0.0050
[BC pretrain] step 76500 | loss: 0.0039
[BC pretrain] step 77000 | loss: 0.0038
[BC pretrain] step 77500 | loss: 0.0067
[BC pretrain] step 78000 | loss: 0.0037
[BC pretrain] step 78500 | loss: 0.0078
[BC pretrain] step 79000 | loss: 0.0048
[BC pretrain] step 79500 | loss: 0.0041
[BC pretrain] step 80000 | loss: 0.0054
[BC pretrain] step 80500 | loss: 0.0042
[BC pretrain] step 81000 | loss: 0.0069
[BC pretrain] step 81500 | loss: 0.0031
[BC pretrain] step 82000 | loss: 0.0044
[BC pretrain] step 82500 | loss: 0.0034
[BC pretrain] step 83000 | loss: 0.0057
[BC pretrain] step 83500 | loss: 0.0056
[BC pretrain] step 84000 | loss: 0.0058
[BC pretrain] step 84500 | loss: 0.0069
[BC pretrain] step 85000 | loss: 0.0045
[BC pretrain] step 85500 | loss: 0.0061
[BC pretrain] step 86000 | loss: 0.0061
[BC pretrain] step 86500 | loss: 0.0078
[BC pretrain] step 87000 | loss: 0.0046
[BC pretrain] step 87500 | loss: 0.0041
[BC pretrain] step 88000 | loss: 0.0038
[BC pretrain] step 88500 | loss: 0.0043
[BC pretrain] step 89000 | loss: 0.0039
[BC pretrain] step 89500 | loss: 0.0060
[BC pretrain] step 90000 | loss: 0.0042
[BC pretrain] step 90500 | loss: 0.0057
[BC pretrain] step 91000 | loss: 0.0050
[BC pretrain] step 91500 | loss: 0.0060
[BC pretrain] step 92000 | loss: 0.0052
[BC pretrain] step 92500 | loss: 0.0041
[BC pretrain] step 93000 | loss: 0.0048
[BC pretrain] step 93500 | loss: 0.0050
[BC pretrain] step 94000 | loss: 0.0047
[BC pretrain] step 94500 | loss: 0.0054
[BC pretrain] step 95000 | loss: 0.0047
[BC pretrain] step 95500 | loss: 0.0040
[BC pretrain] step 96000 | loss: 0.0033
[BC pretrain] step 96500 | loss: 0.0046
[BC pretrain] step 97000 | loss: 0.0036
[BC pretrain] step 97500 | loss: 0.0051
[BC pretrain] step 98000 | loss: 0.0047
[BC pretrain] step 98500 | loss: 0.0060
[BC pretrain] step 99000 | loss: 0.0044
[BC pretrain] step 99500 | loss: 0.0047
Ïó¨Îü¨ Ï£ºÌñâ Îç∞Ïù¥ÌÑ∞Î°ú mcnet ÌïôÏäµ
data filling start
